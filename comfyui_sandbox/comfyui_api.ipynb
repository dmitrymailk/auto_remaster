{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416fbf8e-28cb-4a33-85a4-ac04ad63f13c\n"
     ]
    }
   ],
   "source": [
    "# This is an example that uses the websockets api to know when a prompt execution is done\n",
    "# Once the prompt execution is done it downloads the images using the /history endpoint\n",
    "# https://github.com/Nuked88/DreamingAI/blob/main/dreaminAI_websockets_api_example.py\n",
    "import websocket  # NOTE: websocket-client (https://github.com/websocket-client/websocket-client)\n",
    "import uuid\n",
    "import json\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import requests\n",
    "\n",
    "server_address = \"127.0.0.1:8188\"\n",
    "client_id = str(uuid.uuid4())\n",
    "\n",
    "\n",
    "def queue_prompt(prompt):\n",
    "    p = {\"prompt\": prompt, \"client_id\": client_id}\n",
    "    data = json.dumps(p).encode(\"utf-8\")\n",
    "    req = urllib.request.Request(\"http://{}/prompt\".format(server_address), data=data)\n",
    "    return json.loads(urllib.request.urlopen(req).read())\n",
    "\n",
    "\n",
    "def get_image(filename, subfolder, folder_type):\n",
    "    data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n",
    "    url_values = urllib.parse.urlencode(data)\n",
    "    with urllib.request.urlopen(\n",
    "        \"http://{}/view?{}\".format(server_address, url_values)\n",
    "    ) as response:\n",
    "        return response.read()\n",
    "\n",
    "\n",
    "def get_history(prompt_id):\n",
    "    with urllib.request.urlopen(\n",
    "        \"http://{}/history/{}\".format(server_address, prompt_id)\n",
    "    ) as response:\n",
    "        return json.loads(response.read())\n",
    "\n",
    "\n",
    "def get_images(ws, prompt):\n",
    "    prompt_id = queue_prompt(prompt)[\"prompt_id\"]\n",
    "    output_images = {}\n",
    "    while True:\n",
    "        out = ws.recv()\n",
    "        if isinstance(out, str):\n",
    "            message = json.loads(out)\n",
    "            if message[\"type\"] == \"executing\":\n",
    "                data = message[\"data\"]\n",
    "                if data[\"node\"] is None and data[\"prompt_id\"] == prompt_id:\n",
    "                    break  # Execution is done\n",
    "        else:\n",
    "            continue  # previews are binary data\n",
    "\n",
    "    history = get_history(prompt_id)[prompt_id]\n",
    "    for o in history[\"outputs\"]:\n",
    "        for node_id in history[\"outputs\"]:\n",
    "            node_output = history[\"outputs\"][node_id]\n",
    "            if \"images\" in node_output:\n",
    "                images_output = []\n",
    "                for image in node_output[\"images\"]:\n",
    "                    image_data = get_image(\n",
    "                        image[\"filename\"], image[\"subfolder\"], image[\"type\"]\n",
    "                    )\n",
    "                    images_output.append(image_data)\n",
    "            output_images[node_id] = images_output\n",
    "\n",
    "    return output_images\n",
    "\n",
    "\n",
    "# workflow_path = \"showcases/showcase_9/nfs_canny_normal_map_sdxl_api_1.json\"\n",
    "workflow_path = \"showcases/showcase_9/nfs_canny_normal_map_sdxl_batch_list_api.json\"\n",
    "# upload an image\n",
    "with open(workflow_path, \"r\") as f:\n",
    "    workflow = json.load(f)\n",
    "\n",
    "workflow[\"240\"][\"inputs\"][\"steps\"] = 5\n",
    "workflow[\"253\"][\"inputs\"][\"image_load_cap\"] = 4\n",
    "# start\n",
    "workflow[\"256\"][\"inputs\"][\"int\"] = 170\n",
    "workflow[\"258\"][\"inputs\"][\"filename_prefix\"] = f\"nfs_4screens_6_sdxl_{client_id}\"\n",
    "\n",
    "print(client_id)\n",
    "ws = websocket.WebSocket()\n",
    "ws.connect(\"ws://{}/ws?clientId={}\".format(server_address, client_id))\n",
    "images = get_images(ws, workflow)\n",
    "\n",
    "# Commented out code to display the output images:\n",
    "images_list = []\n",
    "for node_id in images:\n",
    "    for image_data in images[node_id]:\n",
    "        from PIL import Image\n",
    "        import io\n",
    "\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        # image.show()\n",
    "        images_list.append(image)\n",
    "        # save image\n",
    "        # image.save(f\"{node_id}-{seed}.png\")\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from more_itertools import chunked\n",
    "\n",
    "\n",
    "dataset = \"/code/comfyui_sandbox/video_renders/render_nfs_4screens_6\"\n",
    "target_save_path_1 = \"/code/comfyui_sandbox/video_renders/render_nfs_4screens_6_test\"\n",
    "original_images = sorted(list(Path(dataset).glob(\"*.png\")))\n",
    "target_images = sorted(list(Path(target_save_path_1).glob(\"*.png\")))\n",
    "\n",
    "total_parts = 4\n",
    "original_images_parts = list(\n",
    "    chunked(\n",
    "        original_images,\n",
    "        len(original_images) // total_parts + 1,\n",
    "    )\n",
    ")\n",
    "\n",
    "part_num = 0\n",
    "original_images_part = original_images_parts[part_num]\n",
    "target_images_names = set([item.stem for item in target_images])\n",
    "images_to_process = [\n",
    "    item for item in original_images_part if not item.stem in target_images_names\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_num = 0\n",
    "original_images_part = original_images_parts[part_num]\n",
    "target_images_names = set([item.stem for item in target_images])\n",
    "images_to_process = [\n",
    "    item for item in original_images_part if not item.stem in target_images_names\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000007.png')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_to_process[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000000001', '000000002', '000000003', '000000004', '000000005', '000000006'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_images_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000007.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000008.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000009.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000010.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([str(item) for item in images_to_process[:4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ComfyUI Worker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000003.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000004.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000005.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000006.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000007.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000008.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000009.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000010.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000011.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000012.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000013.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000014.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000015.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000016.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000017.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000018.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000019.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000020.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000021.png\n",
      "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000022.png\n",
      "67d8822b-f303-4875-af14-ef0ef3725059\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from more_itertools import chunked\n",
    "import websocket\n",
    "import uuid\n",
    "import json\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import requests\n",
    "import io\n",
    "\n",
    "\n",
    "class ComfyUIImageAPI:\n",
    "    def __init__(\n",
    "        self,\n",
    "        server_address=\"127.0.0.1:8188\",\n",
    "        workflow_path=\"\",\n",
    "    ):\n",
    "        self.server_address = server_address\n",
    "        self.client_id = str(uuid.uuid4())\n",
    "        self.workflow_path = workflow_path\n",
    "\n",
    "    def queue_prompt(\n",
    "        self,\n",
    "        prompt,\n",
    "    ):\n",
    "        p = {\"prompt\": prompt, \"client_id\": self.client_id}\n",
    "        data = json.dumps(p).encode(\"utf-8\")\n",
    "        req = urllib.request.Request(\n",
    "            \"http://{}/prompt\".format(self.server_address), data=data\n",
    "        )\n",
    "        return json.loads(urllib.request.urlopen(req).read())\n",
    "\n",
    "    def get_image(\n",
    "        self,\n",
    "        filename,\n",
    "        subfolder,\n",
    "        folder_type,\n",
    "    ):\n",
    "        data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n",
    "        url_values = urllib.parse.urlencode(data)\n",
    "        with urllib.request.urlopen(\n",
    "            \"http://{}/view?{}\".format(self.server_address, url_values)\n",
    "        ) as response:\n",
    "            return response.read()\n",
    "\n",
    "    def get_history(\n",
    "        self,\n",
    "        prompt_id,\n",
    "    ):\n",
    "        with urllib.request.urlopen(\n",
    "            \"http://{}/history/{}\".format(self.server_address, prompt_id)\n",
    "        ) as response:\n",
    "            return json.loads(response.read())\n",
    "\n",
    "    def get_images(\n",
    "        self,\n",
    "        ws,\n",
    "        prompt,\n",
    "    ):\n",
    "        prompt_id = self.queue_prompt(prompt)[\"prompt_id\"]\n",
    "        output_images = {}\n",
    "        while True:\n",
    "            out = ws.recv()\n",
    "            if isinstance(out, str):\n",
    "                message = json.loads(out)\n",
    "                if message[\"type\"] == \"executing\":\n",
    "                    data = message[\"data\"]\n",
    "                    if data[\"node\"] is None and data[\"prompt_id\"] == prompt_id:\n",
    "                        break  # Execution is done\n",
    "            else:\n",
    "                continue  # previews are binary data\n",
    "\n",
    "        history = self.get_history(prompt_id)[prompt_id]\n",
    "        for o in history[\"outputs\"]:\n",
    "            for node_id in history[\"outputs\"]:\n",
    "                node_output = history[\"outputs\"][node_id]\n",
    "                images_output = []\n",
    "                if \"images\" in node_output:\n",
    "                    for image in node_output[\"images\"]:\n",
    "                        image_data = self.get_image(\n",
    "                            image[\"filename\"], image[\"subfolder\"], image[\"type\"]\n",
    "                        )\n",
    "                        images_output.append(image_data)\n",
    "                output_images[node_id] = images_output\n",
    "\n",
    "        return output_images\n",
    "\n",
    "    def process_image_folder(\n",
    "        self,\n",
    "        original_images_path=\"\",\n",
    "        batch_size=4,\n",
    "        target_save_path=\"\",\n",
    "        total_parts=4,\n",
    "        part_num=0,\n",
    "    ):\n",
    "        self.client_id = str(uuid.uuid4())\n",
    "\n",
    "        original_images = sorted(list(Path(original_images_path).glob(\"*.png\")))\n",
    "        target_images = sorted(list(Path(target_save_path).glob(\"*.png\")))\n",
    "\n",
    "        # total_parts = 4\n",
    "        original_images_parts = list(\n",
    "            chunked(\n",
    "                original_images,\n",
    "                len(original_images) // total_parts + 1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # part_num = 0\n",
    "        original_images_part = original_images_parts[part_num]\n",
    "        target_images_names = set([item.stem for item in target_images])\n",
    "        images_to_process = [\n",
    "            item\n",
    "            for item in original_images_part\n",
    "            if not item.stem in target_images_names\n",
    "        ][:batch_size]\n",
    "        if len(images_to_process) == 0:\n",
    "            return \"END\"\n",
    "\n",
    "        with open(self.workflow_path, \"r\") as f:\n",
    "            workflow = json.load(f)\n",
    "\n",
    "        # diffustion steps\n",
    "        # workflow[\"240\"][\"inputs\"][\"steps\"] = 5\n",
    "        workflow[\"201\"][\"inputs\"][\"batch\"] = True\n",
    "        # input images\n",
    "        workflow[\"257\"][\"inputs\"][\"paths\"] = \"\\n\".join(\n",
    "            [str(item) for item in images_to_process]\n",
    "        )\n",
    "        print(workflow[\"257\"][\"inputs\"][\"paths\"])\n",
    "        # save prefix\n",
    "        save_prefix = f\"nfs_4screens_6_sdxl_{self.client_id}\"\n",
    "        workflow[\"258\"][\"inputs\"][\"filename_prefix\"] = save_prefix\n",
    "\n",
    "        print(self.client_id)\n",
    "        ws = websocket.WebSocket()\n",
    "        ws.connect(\n",
    "            \"ws://{}/ws?clientId={}\".format(\n",
    "                self.server_address,\n",
    "                self.client_id,\n",
    "            )\n",
    "        )\n",
    "        images = self.get_images(ws, workflow)\n",
    "\n",
    "        for node_id in images:\n",
    "            for image_data, image_original_path in zip(\n",
    "                images[node_id], images_to_process\n",
    "            ):\n",
    "                image = Image.open(io.BytesIO(image_data))\n",
    "                image.save(f\"{target_save_path}/{image_original_path.stem}.png\")\n",
    "\n",
    "        # clean output images from comfyui\n",
    "        os.system(f\"rm /code/ComfyUI/output/{save_prefix}*.png\")\n",
    "\n",
    "\n",
    "comfy_images_process = ComfyUIImageAPI(\n",
    "    server_address=\"127.0.0.1:8188\",\n",
    "    workflow_path=\"showcases/showcase_9/nfs_canny_normal_map_sdxl_batch_list_api.json\",\n",
    ")\n",
    "dataset = \"/code/comfyui_sandbox/video_renders/render_nfs_4screens_6\"\n",
    "target_save_path_1 = \"/code/comfyui_sandbox/video_renders/render_nfs_4screens_6_sdxl_1\"\n",
    "comfy_images_process.process_image_folder(\n",
    "    original_images_path=dataset,\n",
    "    batch_size=20,\n",
    "    target_save_path=target_save_path_1,\n",
    "    total_parts=4,\n",
    "    part_num=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Upscale v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install websocket-client==1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6165907c6fe4f77a4f76143d6759d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe19336be33495f8c4e842c3a2964dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5392c4ca27f443fb41680baa1a359a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary folder created at: /tmp/tmp8jagvd1w\n",
      "/tmp/tmp8jagvd1w/0000000.png\n",
      "009ac592-cbb7-4fc5-bd27-182cfe304aed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from more_itertools import chunked\n",
    "import websocket\n",
    "import uuid\n",
    "import json\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import requests\n",
    "import io\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "\n",
    "class ComfyUIImageAPIUpscaleV1:\n",
    "    def __init__(\n",
    "        self,\n",
    "        server_address=\"127.0.0.1:8188\",\n",
    "        workflow_path=\"\",\n",
    "    ):\n",
    "        self.server_address = server_address\n",
    "        self.client_id = str(uuid.uuid4())\n",
    "        self.workflow_path = workflow_path\n",
    "\n",
    "    def queue_prompt(\n",
    "        self,\n",
    "        prompt,\n",
    "    ):\n",
    "        p = {\"prompt\": prompt, \"client_id\": self.client_id}\n",
    "        data = json.dumps(p).encode(\"utf-8\")\n",
    "        req = urllib.request.Request(\n",
    "            \"http://{}/prompt\".format(self.server_address), data=data\n",
    "        )\n",
    "        return json.loads(urllib.request.urlopen(req).read())\n",
    "\n",
    "    def get_image(\n",
    "        self,\n",
    "        filename,\n",
    "        subfolder,\n",
    "        folder_type,\n",
    "    ):\n",
    "        data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n",
    "        url_values = urllib.parse.urlencode(data)\n",
    "        with urllib.request.urlopen(\n",
    "            \"http://{}/view?{}\".format(self.server_address, url_values)\n",
    "        ) as response:\n",
    "            return response.read()\n",
    "\n",
    "    def get_history(\n",
    "        self,\n",
    "        prompt_id,\n",
    "    ):\n",
    "        with urllib.request.urlopen(\n",
    "            \"http://{}/history/{}\".format(self.server_address, prompt_id)\n",
    "        ) as response:\n",
    "            return json.loads(response.read())\n",
    "\n",
    "    def get_images(\n",
    "        self,\n",
    "        ws,\n",
    "        prompt,\n",
    "    ):\n",
    "        prompt_id = self.queue_prompt(prompt)[\"prompt_id\"]\n",
    "        output_images = {}\n",
    "        while True:\n",
    "            out = ws.recv()\n",
    "            if isinstance(out, str):\n",
    "                message = json.loads(out)\n",
    "                if message[\"type\"] == \"executing\":\n",
    "                    data = message[\"data\"]\n",
    "                    if data[\"node\"] is None and data[\"prompt_id\"] == prompt_id:\n",
    "                        break  # Execution is done\n",
    "            else:\n",
    "                continue  # previews are binary data\n",
    "\n",
    "        history = self.get_history(prompt_id)[prompt_id]\n",
    "        for o in history[\"outputs\"]:\n",
    "            for node_id in history[\"outputs\"]:\n",
    "                node_output = history[\"outputs\"][node_id]\n",
    "                images_output = []\n",
    "                if \"images\" in node_output:\n",
    "                    for image in node_output[\"images\"]:\n",
    "                        image_data = self.get_image(\n",
    "                            image[\"filename\"], image[\"subfolder\"], image[\"type\"]\n",
    "                        )\n",
    "                        images_output.append(image_data)\n",
    "                output_images[node_id] = images_output\n",
    "\n",
    "        return output_images\n",
    "\n",
    "    def process_image_folder(\n",
    "        self,\n",
    "        dataset: list = None,\n",
    "        batch_size=4,\n",
    "        target_save_path_1=\"\",\n",
    "        target_save_path_2=\"\",\n",
    "        total_parts=4,\n",
    "        part_num=0,\n",
    "    ):\n",
    "        os.system(f\"mkdir -p {target_save_path_1}\")\n",
    "        os.system(f\"mkdir -p {target_save_path_2}\")\n",
    "\n",
    "        # генерируем случайный номер для исполнителя\n",
    "        self.client_id = str(uuid.uuid4())\n",
    "\n",
    "        # original_images = sorted(list(Path(original_images_path).glob(\"*.png\")))\n",
    "        original_images = dataset\n",
    "        target_images = sorted(list(Path(target_save_path_1).glob(\"*.png\")))\n",
    "\n",
    "        # разбиваем на части\n",
    "        # total_parts = 4\n",
    "        original_images_parts = list(\n",
    "            chunked(\n",
    "                [\"{:07d}\".format(i) for i in range(len(original_images))],\n",
    "                len(original_images) // total_parts + 1,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # part_num = 0\n",
    "        # берем в текущем процессе только нужную часть\n",
    "        original_images_part = original_images_parts[part_num]\n",
    "        # составляем уникальный список имен чтобы с ними больше не работать\n",
    "        target_images_names = set([item.stem for item in target_images])\n",
    "        # фильтруем\n",
    "        images_to_process = [\n",
    "            item for item in original_images_part if not item in target_images_names\n",
    "        ][:batch_size]\n",
    "        if len(images_to_process) == 0:\n",
    "            return \"END\"\n",
    "\n",
    "        with open(self.workflow_path, \"r\") as f:\n",
    "            workflow = json.load(f)\n",
    "\n",
    "        # diffustion steps\n",
    "        # workflow[\"240\"][\"inputs\"][\"steps\"] = 5\n",
    "        # workflow[\"201\"][\"inputs\"][\"batch\"] = True\n",
    "        # input images\n",
    "        # создаем временную папку чтобы данные картинки удалились после\n",
    "        # обработки\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            print(f\"Temporary folder created at: {temp_dir}\")\n",
    "            for im_num in images_to_process:\n",
    "                dataset[int(im_num)][\"edited_image\"].save(f\"{temp_dir}/{im_num}.png\")\n",
    "\n",
    "            images_to_process = [\n",
    "                f\"{temp_dir}/{im_num}.png\" for im_num in images_to_process\n",
    "            ]\n",
    "\n",
    "            # создаем батч\n",
    "            workflow[\"268\"][\"inputs\"][\"paths\"] = \"\\n\".join(\n",
    "                # [str(item) for item in images_to_process]\n",
    "                [item for item in images_to_process]\n",
    "            )\n",
    "            print(workflow[\"268\"][\"inputs\"][\"paths\"])\n",
    "            # save prefix\n",
    "            # save_prefix = f\"nfs_4screens_5_sdxl_{self.client_id}\"\n",
    "            # сохраняем\n",
    "            save_prefix = f\"nfs_4screens_6_sdxl_{self.client_id}\"\n",
    "            workflow[\"261\"][\"inputs\"][\"filename_prefix\"] = save_prefix\n",
    "            workflow[\"252\"][\"inputs\"][\"filename_prefix\"] = save_prefix + \"v2\"\n",
    "\n",
    "            print(self.client_id)\n",
    "            ws = websocket.WebSocket()\n",
    "            ws.connect(\n",
    "                \"ws://{}/ws?clientId={}\".format(\n",
    "                    self.server_address,\n",
    "                    self.client_id,\n",
    "                )\n",
    "            )\n",
    "            # получаем изображения\n",
    "            images = self.get_images(ws, workflow)\n",
    "            for node_id in images:\n",
    "                for image_data, image_original_path in zip(\n",
    "                    images[node_id],\n",
    "                    images_to_process,\n",
    "                ):\n",
    "\n",
    "                    image = Image.open(io.BytesIO(image_data))\n",
    "                    if int(node_id) == 272:\n",
    "                        image.save(\n",
    "                            # f\"{target_save_path_1}/{image_original_path.stem}.png\"\n",
    "                            f\"{target_save_path_1}/{Path(image_original_path).stem}.png\"\n",
    "                        )\n",
    "                    if int(node_id) == 270:\n",
    "                        image.save(\n",
    "                            f\"{target_save_path_2}/{Path(image_original_path).stem}.png\"\n",
    "                        )\n",
    "\n",
    "            # clean output images from comfyui\n",
    "            # os.system(f\"rm /code/ComfyUI/output/{save_prefix}*.png\")\n",
    "            # os.system(f\"rm /code/ComfyUI/output/{save_prefix+'v2'}*.png\")\n",
    "\n",
    "\n",
    "comfy_images_process = ComfyUIImageAPIUpscaleV1(\n",
    "    server_address=\"127.0.0.1:8188\",\n",
    "    workflow_path=\"/code/showcases/showcase_10/workflow_ultimate_upscale_simple_nfs_mix_api_v3.json\",\n",
    ")\n",
    "# original_images_path = (\n",
    "#     \"/code/comfyui_sandbox/video_renders/render_nfs_4screens_5_sdxl_1\"\n",
    "# )\n",
    "target_save_path_1 = (\n",
    "    \"/code/comfyui_sandbox/video_renders/render_nfs_4screens_6_sdxl_1_upscale_1x\"\n",
    ")\n",
    "target_save_path_2 = (\n",
    "    \"/code/comfyui_sandbox/video_renders/render_nfs_4screens_6_sdxl_1_upscale_2x\"\n",
    ")\n",
    "\n",
    "# port = 8188\n",
    "# port = 1337\n",
    "# port = 1338\n",
    "# port = 1339\n",
    "# comfy_images_process = ComfyUIImageAPI(\n",
    "#     server_address=f\"127.0.0.1:{port}\",\n",
    "#     # workflow_path=\"showcases/showcase_9/nfs_canny_normal_map_sdxl_batch_list_api.json\",\n",
    "#     workflow_path=\"showcases/showcase_9/nfs_canny_normal_map_sdxl_batch_list_api_v2.json\",\n",
    "# )\n",
    "# original_images_path = \"/code/comfyui_sandbox/video_renders/render_nfs_4screens_6\"\n",
    "# target_save_path = \"/code/comfyui_sandbox/video_renders/render_nfs_4screens_6_sdxl_1\"\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     result = \"\"\n",
    "#     while result != \"END\":\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# dataset_name = \"dim/nfs_pix2pix_1920_1080_v5\"\n",
    "dataset_name = \"dim/nfs_pix2pix_1920_1080_v6\"\n",
    "dataset = load_dataset(\n",
    "    dataset_name,\n",
    "    # cache_dir=\"/code/dataset/nfs_pix2pix_1920_1080_v5\",\n",
    "    cache_dir=\"/code/dataset/nfs_pix2pix_1920_1080_v6\",\n",
    ")\n",
    "dataset = dataset[\"train\"]\n",
    "\n",
    "result = comfy_images_process.process_image_folder(\n",
    "    dataset=dataset,\n",
    "    batch_size=1,\n",
    "    target_save_path_1=target_save_path_1,\n",
    "    target_save_path_2=target_save_path_2,\n",
    "    total_parts=50,\n",
    "    part_num=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(14+4*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\"0000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'process_folder'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"comfyui_sandbox/process_folder.py\").stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary folder created at: /tmp/tmpq2hybjoe\n",
      "Folder exists? False\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# The folder is created here\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    print(f\"Temporary folder created at: {temp_dir}\")\n",
    "\n",
    "    # You can now create files inside it\n",
    "    file_path = os.path.join(temp_dir, \"test_file.txt\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"Hello World\")\n",
    "\n",
    "# As soon as you un-indent here, the folder 'temp_dir' is DELETED automatically.\n",
    "print(f\"Folder exists? {os.path.exists(temp_dir)}\")  # Will print False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpq2hybjoe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_code (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
