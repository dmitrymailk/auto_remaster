# Copyright (c) 2025 Hansheng Chen

import os
import argparse
import tqdm
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import torch

torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

from lakonlab.models import GMFlowMLP2DDenoiser, GMFlow
from lakonlab.datasets import CheckerboardData


D = 2
EPS = 1e-4
T_SCALE = 1000
N_TEST_SAMPLES = 1e6


def parse_args():
    parser = argparse.ArgumentParser(
        description="A minimal GMFlow trainer using the 2D checkerboard dataset (without transition loss and EMA)."
    )
    parser.add_argument(
        "-k", type=int, default=32, help="number of Gasussian components"
    )
    parser.add_argument("--batch-size", type=int, default=4096, help="batch size")
    parser.add_argument(
        "--num-iters", type=int, default=50000, help="number of iterations"
    )
    parser.add_argument("--lr", type=float, default=2e-4, help="learning rate")
    parser.add_argument("--nfe", type=int, default=8, help="number of sampling steps")
    parser.add_argument(
        "--out", type=str, default="gmflow_toymodel.png", help="output file path"
    )
    args = parser.parse_args()
    return args


def gm_kl_loss(gm, sample, eps=1e-4):
    """
    Gaussian mixture KL divergence loss (without constant terms), a.k.a. GM NLL loss.

    Args:
        gm (dict):
            means (torch.Tensor): (bs, num_gaussians, D)
            logstds (torch.Tensor): (bs, 1, 1)
            logweights (torch.Tensor): (bs, num_gaussians, 1)
        sample (torch.Tensor): (bs, D)

    Returns:
        torch.Tensor: (bs, )
    """
    means = gm["means"]
    logstds = gm["logstds"]
    logweights = gm["logweights"]

    inverse_stds = torch.exp(-logstds).clamp(max=1 / eps)
    diff_weighted = (
        sample.unsqueeze(-2) - means
    ) * inverse_stds  # (bs, num_gaussians, D)
    gaussian_ll = (-0.5 * diff_weighted.square() - logstds).sum(
        dim=-1
    )  # (bs, num_gaussians)
    gm_nll = -torch.logsumexp(gaussian_ll + logweights.squeeze(-1), dim=-1)  # (bs, )
    return gm_nll


def main():
    args = parse_args()
    num_gaussians = args.k
    batch_size = args.batch_size
    num_iters = args.num_iters
    lr = args.lr
    num_steps = args.nfe
    out_path = args.out

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    denoiser = GMFlowMLP2DDenoiser(num_gaussians=num_gaussians).to(device)
    dataset = CheckerboardData(scale=4)
    sample_batches = dataset.samples.to(device).split(batch_size, dim=0)
    optimizer = torch.optim.Adam(denoiser.parameters(), lr=lr)

    for i in range(num_iters):
        x_0 = sample_batches[i % len(sample_batches)]
        optimizer.zero_grad()

        t = torch.rand(x_0.size(0), device=device).clamp(min=EPS)
        noise = torch.randn_like(x_0)

        sigma = t
        alpha = 1 - sigma
        x_t = alpha.unsqueeze(-1) * x_0 + sigma.unsqueeze(-1) * noise
        u = noise - x_0  # equal to (x_t - x_0) / sigma

        u_gm = denoiser(x_t, t * T_SCALE)
        loss = gm_kl_loss(u_gm, u)

        loss.mean().backward()
        optimizer.step()

        if i % 1000 == 0:
            print(f"Iter {i}, loss: {loss.mean().item()}")

    print("Training finished. Starting inference...")

    torch.set_grad_enabled(False)

    model = GMFlow(
        denoising=denoiser,
        num_timesteps=T_SCALE,
        test_cfg=dict(  # use 2nd-order GM-SDE solver
            output_mode="sample", sampler="FlowSDE", num_timesteps=num_steps, order=2
        ),
    ).eval()

    samples = []
    for _ in tqdm.tqdm(range(int(N_TEST_SAMPLES // batch_size))):
        noise = torch.randn((batch_size, D, 1, 1), device=device)
        samples.append(
            model.forward_test(noise=noise).reshape(batch_size, D).cpu().numpy()
        )
    samples = np.concatenate(samples, axis=0)

    histo, _, _ = np.histogram2d(
        samples[:, 0], samples[:, 1], bins=200, range=[[-4.2, 4.2], [-4.2, 4.2]]
    )
    histo_image = (histo.T[::-1] / 160).clip(0, 1)
    histo_image = cm.viridis(histo_image)
    histo_image = np.round(histo_image * 255).clip(min=0, max=255).astype(np.uint8)

    out_path = os.path.abspath(out_path)
    out_dir = os.path.dirname(out_path)
    os.makedirs(out_dir, exist_ok=True)
    plt.imsave(out_path, histo_image)

    print(f"Sample histogram saved to {out_path}.")


if __name__ == "__main__":
    main()
