Да, ты абсолютно прав. Стандартный CFG удваивает вычислительную стоимость, потому что на каждый шаг времени $t$ тебе нужно делать два прогона (forward pass) через нейросеть (один с промптом, один без).

Если твоя цель — **Real-Time (1 шаг, 1 прогон)**, то стандартный CFG тебе не подходит. Но есть решение.

Тебе нужна **Guidance Distillation (Дистилляция Гайденса)**.

### Как это работает

Идея в том, чтобы «запечь» эффект CFG прямо в веса модели или обучить модель предсказывать уже «усиленный» вектор сразу.

Если ты тренируешь модель с нуля или можешь её дообучить (finetune), ты делаешь следующее:

1.  **Учитель (Teacher):** У тебя есть твоя обычная Flow Matching модель, которая требует CFG.
2.  **Ученик (Student):** Ты создаешь копию этой модели (или берешь архитектуру поменьше).
3.  **Процесс обучения:**
    *   Ты берешь зашумленный вход $x_t$.
    *   С помощью Учителя вычисляешь «идеальный» вектор с применением CFG (делаешь 2 прогона и вычитаешь):
        $$ v_{target} = v_{empty} + w \cdot (v_{text} - v_{empty}) $$
    *   Заставляешь Ученика предсказать сразу этот $v_{target}$, видя только $x_t$ и текст.
    *   Loss = $|| v_{student}(x_t, \text{text}) - v_{target} ||^2$

### Результат
После обучения модель-ученик сразу выдает вектор, который уже содержит в себе силу гайденса.
*   **Инференс:** 1 прогон.
*   **Качество:** Как с CFG.
*   **Настройка:** Ты теряешь возможность крутить ползунок $w$ (CFG Scale) на лету, так как он «запечен» в веса (обычно выбирают фиксированное значение, например $w=4$ или $w=7$).

---

### Продвинутый вариант: $w$ как входной параметр

Чтобы не терять "ручку громкости", в современных методах (например, в **Stable Diffusion 3** или **Flux**) делают еще хитрее при дистилляции:

Они подают желаемый **guidance scale $w$** прямо как входной параметр в нейросеть (как time embedding).

$$ v_{student}(x_t, t, \text{text}, w) \approx v_{empty} + w \cdot (v_{text} - v_{empty}) $$

Тогда в реальном времени ты:
1.  Подаешь шум, текст и число $w$ (например, 5.0).
2.  Делаешь **один** прогон.
3.  Нейросеть сама внутри себя "понимает", как сместить вектор, и выдает готовый результат.

### Пример из жизни: Flux.1 Schnell
Модель **Flux.1 Schnell** (версия для скорости) работает именно так. Она предназначена для генерации за 1-4 шага. В ней используется дистилляция, поэтому ей **не нужен** классический двойной прогон CFG. Она выдает готовый вектор за один проход.

### Резюме для твоей задачи

Если ты делаешь Real-Time с Flow Matching и ограничен 1 шагом (One-Step Generation):

1.  Ты **не можешь** использовать классическую формулу $v_{uncond} + w(diff)$ во время работы (инференса), так как это 2 прогона.
2.  Тебе нужно использовать **Distilled Model** (дистиллированную модель).
3.  Если ты обучаешь модель сам: добавь этап **Guidance Distillation**. Обучи модель предсказывать результат формулы CFG.
4.  Если ты берешь готовую: ищи модели с приставкой "Turbo", "Distilled" или "Schnell". В них CFG уже внутри.