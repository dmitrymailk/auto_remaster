{
  "4": {
    "inputs": {
      "ckpt_name": "Juggernaut_X_RunDiffusion_Hyper.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "6": {
    "inputs": {
      "text": "photograph rain weather, a car driving on a road, rain, natural trees, realistic trees, beautiful gray sky, massive leaves and puddles on road, big cracks in the asphalt, very detailed autumn grass, old houses with cracks, broken windows 400mm . cinematic 8k epic detailed 8k epic detailed photograph shot on kodak detailed cinematic hbo dark moody, 40mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage, big raindrops on a camera lenses, real world location, lowfi,  Kodak Vision3 500T analog film stock style, AnalogRedmAF, Chern4byl enviroment",
      "clip": [
        "179",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive)"
    }
  },
  "7": {
    "inputs": {
      "text": "sun, (videogame:1.2), game, bokeh, depth of field, blurry, cropped, regular face, saturated, contrast, deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, (((deformed cars)))",
      "clip": [
        "179",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative)"
    }
  },
  "131": {
    "inputs": {
      "pixels": [
        "235",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "141": {
    "inputs": {
      "switch_1": "On",
      "controlnet_1": "None",
      "controlnet_strength_1": 0.4,
      "start_percent_1": 0,
      "end_percent_1": 1,
      "switch_2": "On",
      "controlnet_2": "xinsir_controlnet-canny-sdxl-1.0.safetensors",
      "controlnet_strength_2": 1,
      "start_percent_2": 0,
      "end_percent_2": 1,
      "switch_3": "On",
      "controlnet_3": "diffusion_pytorch_model_promax.safetensors",
      "controlnet_strength_3": 0.9,
      "start_percent_3": 0,
      "end_percent_3": 1,
      "image_1": [
        "248",
        0
      ],
      "image_2": [
        "197",
        0
      ],
      "image_3": [
        "197",
        0
      ]
    },
    "class_type": "CR Multi-ControlNet Stack",
    "_meta": {
      "title": "üïπÔ∏è CR Multi-ControlNet Stack"
    }
  },
  "172": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": [
        "4",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter Unified Loader"
    }
  },
  "177": {
    "inputs": {
      "weight_style": 0.22,
      "weight_composition": 1.3800000000000001,
      "expand_style": true,
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "172",
        0
      ],
      "ipadapter": [
        "172",
        1
      ],
      "image_style": [
        "235",
        0
      ],
      "image_composition": [
        "235",
        0
      ]
    },
    "class_type": "IPAdapterStyleComposition",
    "_meta": {
      "title": "IPAdapter Style & Composition SDXL"
    }
  },
  "178": {
    "inputs": {
      "switch_1": "On",
      "lora_name_1": "aidmaMidjourneyV6.1-v0.1.safetensors",
      "model_weight_1": 0.5,
      "clip_weight_1": 1,
      "switch_2": "On",
      "lora_name_2": "PostApocalyptic_Chernobyl_v3.safetensors",
      "model_weight_2": 0.5,
      "clip_weight_2": 0,
      "switch_3": "Off",
      "lora_name_3": "None",
      "model_weight_3": 1,
      "clip_weight_3": 1,
      "lora_stack": [
        "180",
        0
      ]
    },
    "class_type": "CR LoRA Stack",
    "_meta": {
      "title": "üíä CR LoRA Stack"
    }
  },
  "179": {
    "inputs": {
      "model": [
        "177",
        0
      ],
      "clip": [
        "4",
        1
      ],
      "lora_stack": [
        "178",
        0
      ]
    },
    "class_type": "CR Apply LoRA Stack",
    "_meta": {
      "title": "üíä CR Apply LoRA Stack"
    }
  },
  "180": {
    "inputs": {
      "switch_1": "On",
      "lora_name_1": "Kodak VISION3 250D analog film stock style v2.safetensors",
      "model_weight_1": 0.63,
      "clip_weight_1": 1,
      "switch_2": "Off",
      "lora_name_2": "None",
      "model_weight_2": 0.1,
      "clip_weight_2": 1,
      "switch_3": "On",
      "lora_name_3": "AnalogRedmondV2-Analog-AnalogRedmAF.safetensors",
      "model_weight_3": 0.52,
      "clip_weight_3": 1
    },
    "class_type": "CR LoRA Stack",
    "_meta": {
      "title": "üíä CR LoRA Stack"
    }
  },
  "194": {
    "inputs": {
      "model": "sam2.1_hiera_large.safetensors",
      "segmentor": "single_image",
      "device": "cuda",
      "precision": "bf16"
    },
    "class_type": "DownloadAndLoadSAM2Model",
    "_meta": {
      "title": "(Down)Load SAM2Model"
    }
  },
  "197": {
    "inputs": {
      "mask_opacity": 0.8200000000000001,
      "mask_color": "0, 0, 0",
      "pass_through": true,
      "image": [
        "221",
        0
      ],
      "mask": [
        "203",
        0
      ]
    },
    "class_type": "ImageAndMaskPreview",
    "_meta": {
      "title": "ImageAndMaskPreview"
    }
  },
  "198": {
    "inputs": {
      "text_input": "trees",
      "task": "caption_to_phrase_grounding",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 1,
      "do_sample": false,
      "output_mask_select": "",
      "seed": 1116837099312052,
      "image": [
        "235",
        0
      ],
      "florence2_model": [
        "199",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "199": {
    "inputs": {
      "model": "microsoft/Florence-2-large",
      "precision": "bf16",
      "attention": "sdpa"
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "201": {
    "inputs": {
      "index": "",
      "batch": true,
      "data": [
        "198",
        3
      ]
    },
    "class_type": "Florence2toCoordinates",
    "_meta": {
      "title": "Florence2 Coordinates"
    }
  },
  "203": {
    "inputs": {
      "keep_model_loaded": false,
      "individual_objects": true,
      "sam2_model": [
        "194",
        0
      ],
      "image": [
        "235",
        0
      ],
      "bboxes": [
        "201",
        1
      ]
    },
    "class_type": "Sam2Segmentation",
    "_meta": {
      "title": "Sam2Segmentation"
    }
  },
  "219": {
    "inputs": {
      "width": 1920,
      "height": 1080,
      "position": "top-left",
      "x_offset": 0,
      "y_offset": 0,
      "image": [
        "226",
        0
      ]
    },
    "class_type": "ImageCrop+",
    "_meta": {
      "title": "üîß Image Crop"
    }
  },
  "221": {
    "inputs": {
      "width": 1920,
      "height": 1080,
      "position": "top-right",
      "x_offset": 0,
      "y_offset": 0,
      "image": [
        "226",
        0
      ]
    },
    "class_type": "ImageCrop+",
    "_meta": {
      "title": "üîß Image Crop"
    }
  },
  "226": {
    "inputs": {
      "upscale_method": "lanczos",
      "width": 3840,
      "height": 2160,
      "crop": "disabled",
      "image": [
        "257",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "235": {
    "inputs": {
      "width": 1920,
      "height": 1080,
      "position": "bottom-right",
      "x_offset": 0,
      "y_offset": 0,
      "image": [
        "226",
        0
      ]
    },
    "class_type": "ImageCrop+",
    "_meta": {
      "title": "üîß Image Crop"
    }
  },
  "238": {
    "inputs": {
      "width": 1920,
      "height": 1080,
      "position": "bottom-left",
      "x_offset": 0,
      "y_offset": 0,
      "image": [
        "226",
        0
      ]
    },
    "class_type": "ImageCrop+",
    "_meta": {
      "title": "üîß Image Crop"
    }
  },
  "240": {
    "inputs": {
      "seed": 38,
      "steps": 20,
      "cfg": 5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.55,
      "model": [
        "179",
        0
      ],
      "positive": [
        "243",
        0
      ],
      "negative": [
        "243",
        1
      ],
      "latent_image": [
        "131",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "241": {
    "inputs": {
      "switch_1": "Off",
      "controlnet_1": "None",
      "controlnet_strength_1": 0.9,
      "start_percent_1": 0,
      "end_percent_1": 1,
      "switch_2": "Off",
      "controlnet_2": "None",
      "controlnet_strength_2": 0.5,
      "start_percent_2": 0,
      "end_percent_2": 1,
      "switch_3": "On",
      "controlnet_3": "diffusion_pytorch_model_promax.safetensors",
      "controlnet_strength_3": 0.6,
      "start_percent_3": 0,
      "end_percent_3": 1,
      "image_1": [
        "197",
        0
      ],
      "image_2": [
        "248",
        0
      ],
      "image_3": [
        "238",
        0
      ],
      "controlnet_stack": [
        "141",
        0
      ]
    },
    "class_type": "CR Multi-ControlNet Stack",
    "_meta": {
      "title": "üïπÔ∏è CR Multi-ControlNet Stack"
    }
  },
  "243": {
    "inputs": {
      "switch": "On",
      "base_positive": [
        "6",
        0
      ],
      "base_negative": [
        "7",
        0
      ],
      "controlnet_stack": [
        "241",
        0
      ]
    },
    "class_type": "CR Apply Multi-ControlNet",
    "_meta": {
      "title": "üïπÔ∏è CR Apply Multi-ControlNet"
    }
  },
  "244": {
    "inputs": {
      "samples": [
        "240",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "248": {
    "inputs": {
      "mask_opacity": 0.97,
      "mask_color": "0, 0, 0",
      "pass_through": true,
      "image": [
        "219",
        0
      ],
      "mask": [
        "203",
        0
      ]
    },
    "class_type": "ImageAndMaskPreview",
    "_meta": {
      "title": "ImageAndMaskPreview"
    }
  },
  "253": {
    "inputs": {
      "directory": "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6",
      "image_load_cap": 8,
      "skip_first_images": [
        "256",
        0
      ],
      "select_every_nth": 1
    },
    "class_type": "VHS_LoadImagesPath",
    "_meta": {
      "title": "Load Images (Path) üé•üÖ•üÖóüÖ¢"
    }
  },
  "255": {
    "inputs": {
      "number_type": "integer",
      "mode": "increment",
      "start": 0,
      "stop": 250,
      "step": 1
    },
    "class_type": "Number Counter",
    "_meta": {
      "title": "Number Counter"
    }
  },
  "256": {
    "inputs": {
      "int": 200
    },
    "class_type": "ttN int",
    "_meta": {
      "title": "int"
    }
  },
  "257": {
    "inputs": {
      "paths": "/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000001.png\n/code/comfyui_sandbox/video_renders/render_nfs_4screens_6/000000006.png",
      "ignore_missing_images": "false"
    },
    "class_type": "JWLoadImagesFromString",
    "_meta": {
      "title": "Load Images From String"
    }
  },
  "258": {
    "inputs": {
      "filename_prefix": "nfs_4screens_6_sdxl",
      "images": [
        "244",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  }
}